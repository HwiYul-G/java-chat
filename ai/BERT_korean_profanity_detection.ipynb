{"cells":[{"cell_type":"markdown","metadata":{"id":"22CgKTEpKoco"},"source":["## 설치 및 세팅\n","- google colab 이용"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2903,"status":"ok","timestamp":1726147745670,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"s6OETYbMKXop","outputId":"e6f11e63-4e97-4894-d42f-7bd8a42df56f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2330,"status":"ok","timestamp":1726147747998,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"yvWN3qwlalDP","outputId":"2a58144b-9789-41bb-c58e-f6bd5a0a6c2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.22.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.2)\n","Requirement already satisfied: transformers<4.45.0,>=4.29 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (4.44.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.4.0+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.1)\n","Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (1.26.4)\n","Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.24.6)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.19.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (3.20.2)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.1.99)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.10.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n"]}],"source":["!pip install optimum[exporters]"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7035,"status":"ok","timestamp":1726147755031,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"hLPezvBOKgQD"},"outputs":[],"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726147755031,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"3LI41pRyKg6N","outputId":"18daa157-42b6-40ae-c933-42d631667571"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","Tesla T4\n"]}],"source":["# GPU가 맞게 설정되었는지 확인하는 코드\n","# 올바르게 설정되었다면 Tesla T4라고 출력된다.\n","n_devices = torch.cuda.device_count()\n","print(n_devices)\n","\n","for i in range(n_devices):\n","    print(torch.cuda.get_device_name(i))"]},{"cell_type":"markdown","metadata":{"id":"nHgmVkdeKwV1"},"source":["## 데이터 로드"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726147755032,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"G4tzca5RKnbe","outputId":"fe7dc2d3-523b-4dca-8b0f-11cd3ab8c914"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5824, 2)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 5824,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5824,\n        \"samples\": [\n          \"\\ud2b8\\ub7fc\\ud504 \\uc874\\ub098\\uc80a\\uc5b4\\ubcf4\\uc774\\ub124 \\ub098\\ud640\\ub85c\\uc9d1\\uc5d02 \\ub098\\uc624\\ub358\\ub54c\\ub0d0\",\n          \"\\uc804\\ub77c\\ub3c4\\ub124\",\n          \"\\uc0ac\\ub4dc \\u3137\\u3137\\u3137\\u3137\\u3137\\u3137\\u3137\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"dataset"},"text/html":["\n","  <div id=\"df-4eb41b60-b4cc-4adc-8d26-0c830b61fa4a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>좌배 까는건 ㅇㅂ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>세탁이라고 봐도 된다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eb41b60-b4cc-4adc-8d26-0c830b61fa4a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4eb41b60-b4cc-4adc-8d26-0c830b61fa4a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4eb41b60-b4cc-4adc-8d26-0c830b61fa4a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4899a3e5-a550-441b-b944-5e200523a557\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4899a3e5-a550-441b-b944-5e200523a557')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4899a3e5-a550-441b-b944-5e200523a557 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                        content  label\n","0                                     좌배 까는건 ㅇㅂ      1\n","1                  집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n","2   개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아      1\n","3                                   세탁이라고 봐도 된다      0\n","4                            애새끼가 초딩도 아니고 ㅋㅋㅋㅋ       1"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# 데이터셋 불러오기\n","dataset = pd.read_table('/content/korean_bad_word_dataset.txt', sep='|', skiprows=[455], names=['content', 'label'])\n","print(dataset.shape)\n","dataset.head(5)"]},{"cell_type":"markdown","metadata":{"id":"xup3rFm6K-xN"},"source":["## 데이터 분리 및 전처리\n","- 총 데이터 수: 5,824개\n","- train과 test로 9:1의 비율로 나눈다.\n","- train 전처리 후, train을 train과 validation으로 9:1의 비율로 나눈다.\n","- 결과로 나오는 데이터 수\n","    - train: 4716\n","    - validation: 525\n","    - test: 583"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726147755032,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"sh4SZ30nK9LI","outputId":"743d2bf4-4831-479c-e772-0559ef74f5f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data 크기:  (5241, 2)\n","Test 크기:  (583, 2)\n"]}],"source":["# train + test : 90%, test: 10 %\n","train, test = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","# 데이터 크기 출력\n","print(\"Train data 크기: \", train.shape)\n","print(\"Test 크기: \", test.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726147755032,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"iJ6q9GoMLE1k","outputId":"2b633117-be46-4ac7-f5cd-8fe359bfd358"},"outputs":[{"data":{"text/plain":["['[CLS] 석유 화학은 GS, S-오일, 현대오일뱅크지 [SEP]',\n"," '[CLS] 은교입니다. [SEP]',\n"," '[CLS] 김트루는 디씨네임드야 [SEP]',\n"," '[CLS] ㄴㄴ 그냥 해논 닉이도 구로디지탈산다 키 잘생긴편인데  머하노 인물아깝게 인생짧아 [SEP]',\n"," '[CLS] 존경 스롭넹 와우!!!! [SEP]']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# train set 전처리: BERT의 입력 형식에 맞게 변환\n","sentences = ['[CLS] ' + str(s) + ' [SEP]' for s in train['content']]\n","sentences[:5]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1726147755032,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"r-hq85ngLF1m","outputId":"0d55eb2a-0dd0-4579-bd89-d56704cfe024"},"outputs":[{"data":{"text/plain":["array([0, 0, 0, ..., 0, 1, 0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["labels = train['label'].values\n","labels"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3368,"status":"ok","timestamp":1726147758396,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"VbBmRCgNLG-t","outputId":"ac382d3c-31eb-4362-de35-2b325aa76f81"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["# 서브워드 토크나이저: wrodPiece\n","# 단어를 토큰화할 때 단어 집합에 없는 단어를 쪼개서 ##을 붙여준다.\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in sentences]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726147758397,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"ICP2OPp5LH1-","outputId":"14eb2823-78fb-45dd-e844-a4d084705dc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] 석유 화학은 GS, S-오일, 현대오일뱅크지 [SEP]\n","['[CLS]', '석', '##유', '화', '##학', '##은', 'GS', ',', 'S', '-', '오', '##일', ',', '현대', '##오', '##일', '##뱅', '##크', '##지', '[SEP]']\n"]}],"source":["print(sentences[0])\n","print(tokenized_texts[0])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147758397,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"06ymCkx-LJOR","outputId":"41e4cecb-e29a-4e8c-b9cb-6468b55a68c0"},"outputs":[{"data":{"text/plain":["array([   101,   9426,  42815,   9993,  23321,  10892,  70069,    117,\n","          156,    118,   9580,  18392,    117, 104518,  28188,  18392,\n","       118974,  20308,  12508,    102,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# 문장의 최대 시퀀스를 설정해 정수 인코딩과 제로 패딩 수행\n","MAX_LEN = 128\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1726147758978,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"WUdoVcAsLKjG"},"outputs":[],"source":["# 어텐션 마스크\n","# 0값을 가지는 패딩 토큰에 대해서 어텐션 연산을 불필요하게 수행하지 않도록\n","# 단어와 패딩 토큰을 구분할 수 있게 알려주는 것\n","attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147758978,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"w8eIZYAcLL0T","outputId":"5ce618e0-dfae-4242-bffc-79fc8ccc962b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}],"source":["print(attention_masks[0])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147758978,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"drRxHZ4aLM4i","outputId":"690e19d5-94a9-4c18-97e2-c53e45eed86f"},"outputs":[{"name":"stdout","output_type":"stream","text":["train shape:  (4716, 128)\n","val shape:  (525, 128)\n"]}],"source":["# Train -> Train + Validation 으로 분류하기\n","train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.1, random_state=42)\n","train_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)\n","\n","print(\"train shape: \", train_inputs.shape)\n","print(\"val shape: \", val_inputs.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1726147758978,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"dDJTDC8YLOAd"},"outputs":[],"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","\n","val_inputs = torch.tensor(val_inputs)\n","val_labels = torch.tensor(val_labels)\n","val_masks = torch.tensor(val_masks)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1726147758978,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"kyBAoltVLPCJ"},"outputs":[],"source":["# 입력 데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어서\n","# train_dataloader, val_dataloader라는 입력데이터를 생성한다.\n","batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"xHKTrBB2LRuB"},"source":["## Test set"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":539,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"e28AXh-ELQlL"},"outputs":[],"source":["# [CLS] + 문장 + [SEP]\n","sentences = test['content']\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","# 라벨 데이터\n","labels = test['label'].values\n","\n","# Word 토크나이저 토큰화\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"EvE0SixfLTxO"},"outputs":[],"source":["# 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n","MAX_LEN = 128\n","\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"xJsx3hh6LU_F"},"outputs":[],"source":["# 어텐션 마스크\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"xFtUsHhDLWAT","outputId":"d398d123-999d-4278-df62-c132df0fc935"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_inputs size: torch.Size([583, 128])\n","test_masks size: torch.Size([583, 128])\n","test_labels size: torch.Size([583])\n"]}],"source":["# 파이토치 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(f\"test_inputs size: {test_inputs.shape}\")\n","print(f\"test_masks size: {test_masks.shape}\")\n","print(f\"test_labels size: {test_labels.shape}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"sOkbGevkLW5u"},"outputs":[],"source":["# 배치 사이즈 설정 및 데이터 설정\n","batch_size = 32\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"L9s2xuc8LYn9"},"source":["## Bert 모델 불러오기"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726147759516,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"Td_3e7dwLYEm","outputId":"6c66d741-9c4d-424d-e96b-1dfed78ace72"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1726147760559,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"e-1P7f7pLbta","outputId":"9ff7fa04-1307-4196-bd4e-efd3d3d9ff74"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# pretrained model 불러오기\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1726147761214,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"yUK5ztleLc5e","outputId":"715cb958-c416-43dd-ca4c-8bbd87392747"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# 옵티마이저\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  eps = 1e-8\n","                )\n","\n","# 에폭수\n","epochs = 4\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"]},{"cell_type":"markdown","metadata":{"id":"se5CbEO2Lhi4"},"source":["## 모델 학"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1726147761214,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"fdymsBq1LgpO"},"outputs":[],"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369699,"status":"ok","timestamp":1726148130912,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"RM7mJ0IaLkNm","outputId":"090dfe0a-7478-4590-9987-ebcdb38a90b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","\n","  Average training loss: 0.54\n","  Training epcoh took: 0:01:27\n","\n","Running Validation...\n","  Accuracy: 0.79\n","  Validation took: 0:00:03\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","\n","  Average training loss: 0.38\n","  Training epcoh took: 0:01:29\n","\n","Running Validation...\n","  Accuracy: 0.80\n","  Validation took: 0:00:03\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","\n","  Average training loss: 0.27\n","  Training epcoh took: 0:01:31\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation took: 0:00:03\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:01:31\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation took: 0:00:03\n","\n","Training complete!\n"]}],"source":["#랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","#그래디언트 초기화\n","model.zero_grad()\n","\n","# 학습\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","\n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in val_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # 그래디언트 계산 안함\n","        with torch.no_grad():\n","            # Forward 수행\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","\n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"markdown","metadata":{"id":"xH3mGPlHLm20"},"source":["## 테스트 셋 평가"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3541,"status":"ok","timestamp":1726148134450,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"snK62aaALlef","outputId":"2e03d6ee-1afe-4a1b-874a-ff1ad1b8a05d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Accuracy: 0.83\n","Test took: 0:00:04\n"]}],"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # 그래디언트 계산 안함\n","    with torch.no_grad():\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"]},{"cell_type":"markdown","metadata":{"id":"bqctHQl9Lq77"},"source":["## 새로운 문장 테스트"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1726148134451,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"AiTTSB1FLqap"},"outputs":[],"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1726148134451,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"oH2cAP-KLt-_"},"outputs":[],"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","\n","    # 그래디언트 계산 안함\n","    with torch.no_grad():\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1726148134451,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"Yqf1JC8iLvjf","outputId":"b77f0730-bb6c-4ac1-faa1-de0b8249bbd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-2.2733462  2.191932 ]]\n","비속어O\n"]}],"source":["logits = test_sentences(['ㅅㅂ놈의 새끼들이 담배 존나 피네 시발 지 방안에서 나 피지:)'])\n","print(logits)\n","\n","if np.argmax(logits) == 1 :\n","    print(\"비속어O\")\n","elif np.argmax(logits) == 0 :\n","    print(\"비속어X\")"]},{"cell_type":"markdown","metadata":{"id":"1YPEHGU_LxZL"},"source":["## export the model - onnx\n","- https://medium.com/@keruchen/export-fine-tuned-bert-model-to-onnx-and-inference-using-onnxruntime-bb1ab568b354"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3603,"status":"ok","timestamp":1726148139734,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"24eNoq6dLwkc","outputId":"91c046b2-0977-42c3-929c-18df0a6ab3b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[onnx] in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (3.16.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (4.66.5)\n","Requirement already satisfied: onnxconverter-common in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (1.14.0)\n","Requirement already satisfied: onnxruntime-tools>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (1.7.0)\n","Requirement already satisfied: onnxruntime>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (1.19.2)\n","Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (from transformers[onnx]) (1.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[onnx]) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[onnx]) (4.12.2)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (3.20.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.4.0->transformers[onnx]) (1.13.2)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (1.16.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (9.0.0)\n","Requirement already satisfied: py3nvml in /usr/local/lib/python3.10/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (0.2.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[onnx]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[onnx]) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[onnx]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[onnx]) (2024.8.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx->transformers[onnx]) (1.16.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.4.0->transformers[onnx]) (10.0)\n","Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from py3nvml->onnxruntime-tools>=1.4.2->transformers[onnx]) (0.13.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.4.0->transformers[onnx]) (1.3.0)\n"]}],"source":["!pip install transformers[onnx]"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":5322,"status":"ok","timestamp":1726148145055,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"IqJxzAzlMF3i"},"outputs":[],"source":["# fine-tuned step에서 checkpoint 저장\n","tokenizer.save_pretrained(\"local-pt-checkpoint\")\n","model.save_pretrained(\"local-pt-checkpoint\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16050,"status":"ok","timestamp":1726148161088,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"S3o_4GnQP1Pn","outputId":"a1cf8ccb-ec3a-468b-a1ec-82ed4ea60760"},"outputs":[{"data":{"text/plain":["CompletedProcess(args=['python', '-m', 'transformers.onnx', '--model=local-pt-checkpoint', 'onnx/'], returncode=0)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# local check point를 onnx로 converting\n","import subprocess\n","subprocess.run(f\"python -m transformers.onnx --model=local-pt-checkpoint onnx/\".split())"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22565,"status":"ok","timestamp":1726148183649,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"CMWGP8a9Z5SU","outputId":"148143c5-48a7-4e3a-9dbf-1e2844d3bd7c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Framework not specified. Using pt to export the model.\n","Using the export variant default. Available variants are:\n","    - default: The default ONNX variant.\n","\n","***** Exporting submodel 1/1: BertForSequenceClassification *****\n","Using framework PyTorch: 2.4.0+cu121\n","Overriding 1 configuration item(s)\n","\t- use_cache -> False\n"]},{"data":{"text/plain":["('onnx/tokenizer_config.json',\n"," 'onnx/special_tokens_map.json',\n"," 'onnx/vocab.txt',\n"," 'onnx/added_tokens.json',\n"," 'onnx/tokenizer.json')"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["from optimum.onnxruntime import ORTModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","model_checkpoint = \"local-pt-checkpoint\"\n","save_directory = \"onnx/\"\n","\n","# Load a model from transformers and export it to ONNX\n","ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","# Save the onnx model and tokenizer\n","ort_model.save_pretrained(save_directory)\n","tokenizer.save_pretrained(save_directory)"]},{"cell_type":"markdown","metadata":{"id":"2RTGxXKofvO6"},"source":["## 파일 저장하기"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":40104,"status":"ok","timestamp":1726148484277,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"jqe_iVj8diCp","outputId":"e20a8c22-f3e5-40be-d55a-ff33af67bea4"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_9891b3e9-284e-4aeb-a67a-34f756f8a3f3\", \"onnx_folder.zip\", 661682115)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["## /content/onnx 폴더를 zip으로 다운받기\n","import shutil\n","from google.colab import files\n","\n","# 폴더를 zip으로 압축\n","shutil.make_archive('/content/onnx_folder', 'zip', '/content/onnx')\n","\n","# 압축된 파일을 다운로드\n","files.download('/content/onnx_folder.zip')"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":47105,"status":"ok","timestamp":1726148562751,"user":{"displayName":"김소연","userId":"02763467732873505191"},"user_tz":-540},"id":"2DsmBSP2d67y","outputId":"ddfc71ee-4128-4355-e895-225ed7d442d7"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_761814d9-1847-46d9-8f9d-c99b9c279caf\", \"local-pt-checkpoint.zip\", 661682115)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# 폴더를 zip으로 압축\n","shutil.make_archive('/content/local-pt-checkpoint', 'zip', '/content/onnx')\n","\n","# 압축된 파일을 다운로드\n","files.download('/content/local-pt-checkpoint.zip')"]},{"cell_type":"markdown","metadata":{"id":"MpaGFsuuR2V6"},"source":["## Inference\n","onnxruntime은 inference를 위한 모듈이다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jp-rxZOof0z_"},"outputs":[],"source":["import numpy as np\n","import torch\n","from onnxruntime import InferenceSession\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iMQa4ZKbhJrN"},"outputs":[],"source":["# ONNX 모델 및 토크나이저 로드\n","onnx_model_path = \"onnx/model.onnx\"  # 모델이 저장된 경로\n","tokenizer = AutoTokenizer.from_pretrained(\"onnx/\")  # 저장된 토크나이저 경로\n","\n","# ONNX 모델을 위한 InferenceSession 생성\n","session = InferenceSession(onnx_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UDt83TujhNaQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNWKYa8XoI0+Q2PSWWKa3oE","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
